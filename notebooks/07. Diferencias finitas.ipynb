{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diferencias finitas: cálculo numérico de derivadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el último notebook, vimos que el método de Newton requiere conocer la derivada de una función.\n",
    "En este notebook, veremos una manera (no necesariamente la mejor) de calcular derivadas de funciones de forma numérica: las llamadas **diferencias finitas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Considera una función uni-dimensional $f: \\mathbb{R} \\to \\mathbb{R}$.\n",
    "\n",
    "Escribe, usando notación LaTeX, la definición de la derivada $f'(a)$ de $f$ en el punto $a$, como límite cuando la variable $h$ tiende a $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] Desgraciadamente, **no podemos llevar a cabo el proceso de límite en la computadora**. (Intuitivamente, podemos decir que el proceso de límite es **continuo**, mientras que la computadora maneja cantidades **discretas**.)\n",
    "\n",
    "(i) ¿Cuál solución se te ocurre para esto en términos de la variable $h$? \n",
    "\n",
    "(ii) Impleméntalo con distintos valores de $h$ que tiendan a cero, usando la función `logspace` para que los valores de $h$ estén espaciados de forma logarítmica. Calcula el error del valor que calculas, comparado con una derivada conocida (de una función que sepas derivar analíticamente). Hazlo para diferentes funciones. (¡Escribe una función que haga el cálculo!) ¿Qué podría causar este efecto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] ¿Para qué clase de función el resultado será exacto? Así, efectivamente qué tipo de **aproximación local** de la función estamos usando? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] (i) Desarrolla $f(a + h)$ en una serie de Taylor. Así, rederiva la expresión aproximada que ya obtuviste para la derivada, pero ahora con información sobre **el tamaño del error** que cometes cuando utilizas esa aproximación. Si el error va como $C.h^n$, con $C$ una constante, escribimos $\\mathcal{O}(h^n)$. \n",
    "\n",
    "La aproximación más sencilla (la que viene de la definición de derivada) se llama una aproximación con una **diferencia para adelante** (\"forward difference\").\n",
    "\n",
    "(ii) Ahora expande $f(a+h)$ y $f(a - h)$ en series de Taylor. Así deriva una mejor aproximación a la primera derivada, que se llama la aproximación con **diferencia centrada**. Calcula su error y chécalo numéricamente.  ¿Para qué tipo de funciones es exacta? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] Encuentra una expresión para la segunda derivada y su error; chécalo numéricamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] Cómo podrías encontrar expresiones de más alto orden para la primera derivada? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7] Utiliza una diferencia finita, con una $h$ pequeña, para aproximar la derivada en el método de Newton. ¿Cómo afecta el utilizar una aproximación de la derivada, en lugar del valor exacto, en la tasa de convergencia? Compara los resultados al utilizar los dos tipos de diferencias finitas (para adelante y centrada)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
